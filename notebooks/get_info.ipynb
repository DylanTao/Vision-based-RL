{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1426\n",
      "           sac_1       sac_2       sac_3\n",
      "0     270.111046  263.823288  234.193960\n",
      "1     245.912287  233.495934  249.950285\n",
      "2     262.389610  220.910236  217.985809\n",
      "3     295.181613  220.907664  194.654771\n",
      "4     189.008491  210.446831  233.927512\n",
      "...          ...         ...         ...\n",
      "1445  324.077639  359.683166  416.110693\n",
      "1446  311.747018  274.848683  319.384010\n",
      "1447  333.707120  333.850003  350.060285\n",
      "1448  335.806030  309.782520  972.200730\n",
      "1449  343.276757  373.205076  201.370780\n",
      "\n",
      "[1450 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "model = \"sac\"\n",
    "task = \"stackcube\"\n",
    "directory = Path.cwd().parents[0]\n",
    "training_location = 'training/'\n",
    "liftcube_reward_drq_dir = directory / model/ training_location/ task\n",
    "\n",
    "runs = [1,2,3]\n",
    "sac_data = pd.DataFrame()\n",
    "for run in runs:\n",
    "    run_dir = liftcube_reward_drq_dir / str(run)\n",
    "    run_data = pd.read_csv(run_dir / 'reward_and_length.csv')\n",
    "    # remove episode number column\n",
    "    # print(run_data.columns)\n",
    "    run_data = run_data.drop(columns=['Episode number'])\n",
    "    # rename reward column to \"model + run\"\n",
    "    run_data = run_data.rename(\n",
    "        columns={' Episode reward': model + '_' + str(run)})\n",
    "    # concat with data from other runs\n",
    "    sac_data = pd.concat([sac_data, run_data], axis=1)\n",
    "\n",
    "print(sac_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sac_1 1355.015343909494\n",
      "438\n",
      "sac_2 1240.8730040349476\n",
      "1391\n",
      "sac_3 1264.9550529759076\n",
      "1426\n",
      "max nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# find max of each column\n",
    "for col in sac_data.columns:\n",
    "    print(col, sac_data[col].max())\n",
    "    print(sac_data[col].idxmax()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drq_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Episode num', ' Episode reward'], dtype='object')\n",
      "Index(['Episode num', ' Episode reward'], dtype='object')\n",
      "Index(['Episode num', ' Episode reward'], dtype='object')\n",
      "        drq_v2_1    drq_v2_2    drq_v2_3\n",
      "0     212.222144  260.044503  217.395417\n",
      "1     226.492097  252.852598  221.500634\n",
      "2     248.447022  217.712271  245.243167\n",
      "3     186.949407  219.361466  241.860302\n",
      "4     245.242071  273.262736  258.095783\n",
      "...          ...         ...         ...\n",
      "1494         NaN  308.140030  319.442270\n",
      "1495         NaN  254.610061  252.320055\n",
      "1496         NaN  355.353047  294.825037\n",
      "1497         NaN  293.359635  295.507558\n",
      "1498         NaN  241.366443  234.638163\n",
      "\n",
      "[1499 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "model = \"drq_v2\"\n",
    "task = \"stackcube\"\n",
    "directory = Path.cwd().parents[0]\n",
    "training_location = 'training/'\n",
    "liftcube_reward_drq_dir = directory / model/ training_location/ task\n",
    "\n",
    "runs = [1,2,3]\n",
    "drq_data = pd.DataFrame()\n",
    "for run in runs:\n",
    "    run_dir = liftcube_reward_drq_dir / str(run)\n",
    "    run_data = pd.read_csv(run_dir / 'reward_and_length.csv')\n",
    "    # remove episode number column\n",
    "    print(run_data.columns)\n",
    "    run_data = run_data.drop(columns=['Episode num'])\n",
    "    # rename reward column to \"model + run\"\n",
    "    run_data = run_data.rename(\n",
    "        columns={' Episode reward': model + '_' + str(run)})\n",
    "    # concat with data from other runs\n",
    "    drq_data = pd.concat([drq_data, run_data], axis=1)\n",
    "    # create another column for the average reward\n",
    "    # drq_data[model + '_avg'] = drq_data.mean(axis=1)\n",
    "\n",
    "print(drq_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drq_v2_1 710.6643779126383\n",
      "223\n",
      "drq_v2_2 1050.2096294887676\n",
      "1449\n",
      "drq_v2_3 388.0250911440153\n",
      "1006\n"
     ]
    }
   ],
   "source": [
    "# find max of each column\n",
    "for col in drq_data.columns:\n",
    "    print(col, drq_data[col].max())\n",
    "    print(drq_data[col].idxmax()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drqv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
